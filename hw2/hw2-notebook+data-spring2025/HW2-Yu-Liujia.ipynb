{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d33ac88",
   "metadata": {},
   "source": [
    "# HW2 - Bias in Data and Prediction - DSCI 531 - Spring 2025\n",
    "\n",
    "### Please complete the code or analysis under \"TODO\". 80pts in total. You should run every cell and keep all the outputs before submitting. Failing to include your outputs will result in zero points.\n",
    "### Please keep academic integrity in mind. Plagiarism will be taken seriously.\n",
    "\n",
    "#### Name: Liujia Yu\n",
    "#### USC ID: 4764432021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c56c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c75bf7",
   "metadata": {},
   "source": [
    "## 1. Implement Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c8b61d",
   "metadata": {},
   "source": [
    "### 1.1 Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5455541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You are NOT allowed to use off-the-shelf fairness packages like ai360\n",
    "\n",
    "def stat_parity(preds, sens):\n",
    "    '''\n",
    "    :preds: numpy array of the model predictions. Consisting of 0s and 1s\n",
    "    :sens: numpy array of the sensitive features. Consisting of 0s and 1s\n",
    "    :return: the statistical parity. no need to take the absolute value\n",
    "    '''\n",
    "    \n",
    "    # TODO. 10pts\n",
    "    p_0 = np.mean(preds[sens == 0])\n",
    "    p_1 = np.mean(preds[sens == 1])\n",
    "    return p_0 - p_1\n",
    "\n",
    "\n",
    "def eq_oppo(preds, sens, labels):\n",
    "    '''\n",
    "    :preds: numpy array of the model predictions. Consisting of 0s and 1s\n",
    "    :sens: numpy array of the sensitive features. Consisting of 0s and 1s\n",
    "    :labels: numpy array of the ground truth labels of the outcome. Consisting of 0s and 1s\n",
    "    :return: the equalized odds. no need to take the absolute value\n",
    "    '''\n",
    "    \n",
    "    # TODO. 10pts\n",
    "    # TPR for group of sens is 0\n",
    "    true_posi_mask = (sens == 0) & (labels == 1)\n",
    "    all_posi_cnt = np.sum(labels[sens == 0])\n",
    "    tpr_0 = ( np.sum(preds[true_posi_mask]) / all_posi_cnt ) \\\n",
    "                if all_posi_cnt > 0 else 0 # make sure the divider is not 0\n",
    "\n",
    "    # TPR for group of sens is 1\n",
    "    true_posi_mask = (sens == 1) & (labels == 1)\n",
    "    all_posi_cnt = np.sum(labels[sens == 1])\n",
    "    tpr_1 = ( np.sum(preds[true_posi_mask]) / all_posi_cnt ) \\\n",
    "                if all_posi_cnt > 0 else 0\n",
    "    \n",
    "    tpr_diff = tpr_0 - tpr_1\n",
    "\n",
    "    # FPR for group of sens is 0\n",
    "    false_posi_mask = (sens == 0) & (labels == 0)\n",
    "    all_nega_cnt = np.sum(1 - labels[sens == 0])\n",
    "    fpr_0 = ( np.sum(preds[false_posi_mask]) / all_nega_cnt ) \\\n",
    "                if all_nega_cnt > 0 else 0\n",
    "\n",
    "    # FPR for group of sens is 1\n",
    "    false_posi_mask = (sens == 1) & (labels == 0)\n",
    "    all_nega_cnt = np.sum(1 - labels[sens == 1])\n",
    "    fpr_1 = ( np.sum(preds[false_posi_mask]) / all_nega_cnt ) \\\n",
    "                if all_nega_cnt > 0 else 0\n",
    "    \n",
    "    fpr_diff = fpr_0 - fpr_1\n",
    "\n",
    "    return tpr_diff + fpr_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d3a213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2666666666666667 0.125\n",
      "0.0 -0.5\n",
      "-1.0 -1.0\n"
     ]
    }
   ],
   "source": [
    "# Test your implemented fairness metrics using the code below\n",
    "# Don't change the code in this cell\n",
    "\n",
    "# test case 1\n",
    "preds = np.array([1, 0, 1, 0, 0, 1, 0, 0, 0, 1])\n",
    "sens = np.array([1, 1, 0, 1, 1, 1, 0, 1, 1, 1])\n",
    "labels = np.array([0, 1, 0, 1, 0, 1, 1, 1, 0, 1])\n",
    "print(eq_oppo(preds, sens, labels), stat_parity(preds, sens))\n",
    "\n",
    "# test case 2\n",
    "preds = np.array([1, 1, 0, 1, 0, 1, 0, 0, 1, 1])\n",
    "sens = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "labels = np.array([0, 1, 0, 1, 0, 1, 1, 0, 0, 0])\n",
    "print(eq_oppo(preds, sens, labels), stat_parity(preds, sens))\n",
    "\n",
    "\n",
    "# test case 3\n",
    "preds = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "sens = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "labels = np.array([0, 1, 0, 1, 0, 1, 1, 0, 0, 0])\n",
    "print(eq_oppo(preds, sens, labels), stat_parity(preds, sens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c1b21",
   "metadata": {},
   "source": [
    "### 1.2 Preprocessing DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3aef19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "# def min_max_normalize(df, numerical_cols):\n",
    "#     for col in numerical_cols:\n",
    "#         min_val = df[col].min()\n",
    "#         max_val = df[col].max()\n",
    "#         df[col] = (df[col] - min_val) / (max_val - min_val)\n",
    "#     return df\n",
    "\n",
    "def process_dfs(df_train_x, df_test_x, categ_cols):\n",
    "    '''\n",
    "    Pre-process the features of the training set and the test set, not including the outcome column.\n",
    "    Convert categorical features (nominal & ordinal features) to one-hot encodings.\n",
    "    Normalize the numerical features into [0, 1].\n",
    "    We process training set and the test set together in order to make sure that \n",
    "    the encodings are consistent between them.\n",
    "    For example, if one class is encoded as 001 and another class is encoded as 010 in the training set,\n",
    "    you should follow this mapping for the test set too.\n",
    "    \n",
    "    :df_train: the dataframe of the training data\n",
    "    :df_test: the dataframe of the test data\n",
    "    :categ_cols: the column names of the categorical features. the rest features are treated as numerical ones.\n",
    "    :return: the processed training data and test data, both should be numpy arrays, instead of DataFrames\n",
    "    '''\n",
    "    \n",
    "    # TODO. 10pts\n",
    "    # Create copies to avoid modifying original data\n",
    "    df_train = df_train_x.copy()\n",
    "    df_test = df_test_x.copy()\n",
    "    \n",
    "    # Identify numerical columns (those not in categ_cols)\n",
    "    numeric_cols = [col for col in df_train.columns if col not in categ_cols]\n",
    "    \n",
    "    # Handle categorical features\n",
    "    for col in categ_cols:\n",
    "        # Get all unique values from both train and test sets\n",
    "        unique_values = pd.concat([df_train[col], df_test[col]]).unique()\n",
    "        \n",
    "        # Create dummy variables for both sets \n",
    "        train_dummies = pd.get_dummies(df_train[col], prefix=col, dtype = int)  # sets dtype to int\n",
    "        test_dummies = pd.get_dummies(df_test[col], prefix=col, dtype = int)\n",
    "        \n",
    "        # Ensure both sets have the same dummy columns\n",
    "        # because when dataset is small, some values might be missing therefore can't create certain cols using OneHotEncoding\n",
    "        missing_cols = set(train_dummies.columns) - set(test_dummies.columns)\n",
    "        for c in missing_cols:\n",
    "            test_dummies[c] = 0\n",
    "        missing_cols = set(test_dummies.columns) - set(train_dummies.columns)\n",
    "        for c in missing_cols:\n",
    "            train_dummies[c] = 0\n",
    "            \n",
    "        # Sort columns to ensure same order\n",
    "        train_dummies = train_dummies.reindex(sorted(train_dummies.columns), axis=1)\n",
    "        test_dummies = test_dummies.reindex(sorted(test_dummies.columns), axis=1)\n",
    "        \n",
    "        # Drop original column and add dummy columns\n",
    "        df_train = df_train.drop(col, axis=1)\n",
    "        df_test = df_test.drop(col, axis=1)\n",
    "        df_train = pd.concat([df_train, train_dummies], axis=1)\n",
    "        df_test = pd.concat([df_test, test_dummies], axis=1)\n",
    "    \n",
    "    # Handle numerical features\n",
    "    if numeric_cols:\n",
    "        scaler = MinMaxScaler()\n",
    "        df_train[numeric_cols] = scaler.fit_transform(df_train[numeric_cols])\n",
    "        df_test[numeric_cols] = scaler.transform(df_test[numeric_cols])\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    # print(df_test.columns)    # Note: for test cases the cols are: ['height', 'size_big', 'size_medium', 'size_small', 'color_blue', 'color_red', 'color_yellow']\n",
    "    train_x = df_train.values\n",
    "    test_x = df_test.values\n",
    "    \n",
    "    return train_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b0b715",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71428571 1.         0.         0.         1.         0.\n",
      "  0.        ]\n",
      " [1.         1.         0.         0.         0.         1.\n",
      "  0.        ]\n",
      " [0.         0.         1.         0.         1.         0.\n",
      "  0.        ]\n",
      " [0.28571429 0.         0.         1.         0.         0.\n",
      "  1.        ]]\n",
      "\n",
      "[[1.57142857 1.         0.         0.         0.         1.\n",
      "  0.        ]\n",
      " [0.57142857 0.         0.         1.         1.         0.\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Test your implemented data preprocessing function\n",
    "# DO NOT change the code in this cell\n",
    "\n",
    "df_train_x = pd.DataFrame([\n",
    "    [ 'big', 10, 'blue',],\n",
    "    [ 'big', 12, 'red',],\n",
    "    ['medium', 5, 'blue'],\n",
    "    ['small', 7, 'yellow']\n",
    "], columns=['size', 'height', 'color'])\n",
    "\n",
    "df_test_x = pd.DataFrame([\n",
    "    [ 'big', 16, 'red',],\n",
    "    ['small', 9, 'blue']\n",
    "], columns=['size', 'height', 'color'])\n",
    "\n",
    "train_data_x, test_data_x = process_dfs(df_train_x, df_test_x, categ_cols=['size', 'color'])\n",
    "print(train_data_x)\n",
    "print()\n",
    "print(test_data_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc8867",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34361f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_adult = pd.read_csv('adult-train.csv', sep=', ', engine='python')\n",
    "df_test_adult = pd.read_csv('adult-test.csv', sep=', ', engine='python')\n",
    "df_train_adult['sex'] = df_train_adult['sex'].map({'Male': 0, 'Female': 1})\n",
    "df_test_adult['sex'] = df_test_adult['sex'].map({'Male': 0, 'Female': 1})\n",
    "df_train_adult['income'] = df_train_adult['income'].map({'<=50K': 0, '>50K': 1})\n",
    "df_test_adult['income'] = df_test_adult['income'].map({'<=50K': 0, '>50K': 1})\n",
    "\n",
    "\n",
    "df_train_german = pd.read_csv('german-train.csv')\n",
    "df_test_german = pd.read_csv('german-test.csv')\n",
    "df_train_german['age'] = df_train_german['age'].apply(lambda x: 1 if x >= 33 else 0)\n",
    "df_test_german['age'] = df_test_german['age'].apply(lambda x: 1 if x>=33 else 0)\n",
    "df_train_german['credit_status'] = df_train_german['credit_status'].map({2:0, 1:1})\n",
    "df_test_german['credit_status'] = df_test_german['credit_status'].map({2:0, 1:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498e89dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race  sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    0   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    0   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    0   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    0   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black    1   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  income  \n",
       "0          2174             0              40  United-States       0  \n",
       "1             0             0              13  United-States       0  \n",
       "2             0             0              40  United-States       0  \n",
       "3             0             0              40  United-States       0  \n",
       "4             0             0              40           Cuba       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e950c415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_account</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_account</th>\n",
       "      <th>present_employment_since</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>personal_status_sex</th>\n",
       "      <th>other_debtors</th>\n",
       "      <th>...</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>other_installment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>num_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num_people_liable</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>credit_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A14</td>\n",
       "      <td>21</td>\n",
       "      <td>A32</td>\n",
       "      <td>A41</td>\n",
       "      <td>5248</td>\n",
       "      <td>A65</td>\n",
       "      <td>A73</td>\n",
       "      <td>1</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A123</td>\n",
       "      <td>0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A11</td>\n",
       "      <td>24</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>1987</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A151</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14</td>\n",
       "      <td>36</td>\n",
       "      <td>A32</td>\n",
       "      <td>A49</td>\n",
       "      <td>5742</td>\n",
       "      <td>A62</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A123</td>\n",
       "      <td>0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A14</td>\n",
       "      <td>36</td>\n",
       "      <td>A32</td>\n",
       "      <td>A49</td>\n",
       "      <td>7409</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>3</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>1</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A14</td>\n",
       "      <td>6</td>\n",
       "      <td>A34</td>\n",
       "      <td>A42</td>\n",
       "      <td>1221</td>\n",
       "      <td>A65</td>\n",
       "      <td>A73</td>\n",
       "      <td>1</td>\n",
       "      <td>A94</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  checking_account  duration credit_history purpose  credit_amount  \\\n",
       "0              A14        21            A32     A41           5248   \n",
       "1              A11        24            A32     A43           1987   \n",
       "2              A14        36            A32     A49           5742   \n",
       "3              A14        36            A32     A49           7409   \n",
       "4              A14         6            A34     A42           1221   \n",
       "\n",
       "  savings_account present_employment_since  installment_rate  \\\n",
       "0             A65                      A73                 1   \n",
       "1             A61                      A73                 2   \n",
       "2             A62                      A74                 2   \n",
       "3             A65                      A75                 3   \n",
       "4             A65                      A73                 1   \n",
       "\n",
       "  personal_status_sex other_debtors  ...  property age  \\\n",
       "0                 A93          A101  ...      A123   0   \n",
       "1                 A93          A101  ...      A121   0   \n",
       "2                 A93          A101  ...      A123   0   \n",
       "3                 A93          A101  ...      A122   1   \n",
       "4                 A94          A101  ...      A122   0   \n",
       "\n",
       "   other_installment_plans housing num_credits   job num_people_liable  \\\n",
       "0                     A143    A152           1  A173                 1   \n",
       "1                     A143    A151           1  A172                 2   \n",
       "2                     A143    A152           2  A173                 1   \n",
       "3                     A143    A152           2  A173                 1   \n",
       "4                     A143    A152           2  A173                 1   \n",
       "\n",
       "   telephone foreign_worker credit_status  \n",
       "0       A191           A201             1  \n",
       "1       A191           A201             0  \n",
       "2       A192           A201             1  \n",
       "3       A191           A201             1  \n",
       "4       A191           A201             1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_german.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c297f2",
   "metadata": {},
   "source": [
    "## 3. Explore fairness in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78093a00",
   "metadata": {},
   "source": [
    "### 3.1 statical analysis on protected feature and outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0747aee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3138370951913641 0.11367818442036394\n",
      "0.6636363636363637 0.7594594594594595\n"
     ]
    }
   ],
   "source": [
    "# Adult\n",
    "# calculate the mean income of two protected groups. only use the training data df_train_adult. \n",
    "# TODO. 2pts. The starter code below just indicate what you need to output in your code.\n",
    "mean_income1_adult = np.mean(df_train_adult['income'][df_train_adult['sex'] == 0])\n",
    "mean_income2_adult = np.mean(df_train_adult['income'][df_train_adult['sex'] == 1])\n",
    "\n",
    "print(mean_income1_adult, mean_income2_adult)\n",
    "\n",
    "\n",
    "# German\n",
    "# calculate the mean credit status of two protected groups. only use the training data df_train_german. \n",
    "# TODO. 2pts. The starter code below just indicate what you need to output in your code.\n",
    "mean_credit1_german = np.mean(df_train_german['credit_status'][df_train_german['age'] == 0])\n",
    "mean_credit2_german = np.mean(df_train_german['credit_status'][df_train_german['age'] == 1])\n",
    "\n",
    "print(mean_credit1_german, mean_credit2_german)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9836be9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0053039008376585695\n"
     ]
    }
   ],
   "source": [
    "# t-test between outcome of two protected groups. only use the training data df_train_adult/german.\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "# import math\n",
    "\n",
    "# def manual_t_test(group1, group2):\n",
    "#     mean1, mean2 = sum(group1) / len(group1), sum(group2) / len(group2)\n",
    "#     var1 = sum((x - mean1) ** 2 for x in group1) / (len(group1) - 1)\n",
    "#     var2 = sum((x - mean2) ** 2 for x in group2) / (len(group2) - 1)\n",
    "    \n",
    "#     se = math.sqrt(var1 / len(group1) + var2 / len(group2))\n",
    "#     t_stat = (mean1 - mean2) / se\n",
    "    \n",
    "#     return abs(t_stat)\n",
    "# Notes: This function can't return p-values because we have to search for the distribution table\n",
    "\n",
    "# Adult\n",
    "# TODO. 3pts. The starter code below just indicate what you need to output in your code.\n",
    "male_income = df_train_adult[df_train_adult['sex'] == 0]['income']\n",
    "female_income = df_train_adult[df_train_adult['sex'] == 1]['income']\n",
    "p_value_adult = ttest_ind(male_income, female_income, equal_var=False).pvalue\n",
    "# p_value_adult = manual_t_test(male_income, female_income)\n",
    "\n",
    "# german\n",
    "# TODO. 3pts. The starter code below just indicate what you need to output in your code.\n",
    "young_credit = df_train_german[df_train_german['age'] == 0]['credit_status']\n",
    "older_credit = df_train_german[df_train_german['age'] == 1]['credit_status']\n",
    "p_value_german = ttest_ind(young_credit, older_credit, equal_var=False).pvalue\n",
    "# p_value_german = manual_t_test(young_credit, older_credit)\n",
    "\n",
    "print(p_value_adult, p_value_german)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71338e78",
   "metadata": {},
   "source": [
    "### From the p_values, are the results significant for Adult and German? How do you explain them?\n",
    "### <span style=\"color:red\">Please type your response here.</span> 3pts\n",
    "\n",
    "For the adult dataset, the p-value is almost 0. This suggests a very strong statistical difference between the two sex groups regarding income.It means gender significantly impacts income classification in this dataset, indicating potential bias.\n",
    "\n",
    "For the german dataset, the p-value is 0.0053, which is still much lower than 0.05. It means there exists a statistically significant difference in credit status for different age groups. Age has a non-negligible effect on credit status. Bias might exist in how credit is assigned.\n",
    "\n",
    "**References:**\n",
    "1. [T-Test: What It Is With Multiple Formulas and When To Use Them](https://www.investopedia.com/terms/t/t-test.asp#:~:text=A%20t%2Dtest%20is%20an%20inferential%20statistic%20used%20to%20determine,flipping%20a%20coin%20100%20times.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee79391",
   "metadata": {},
   "source": [
    "### 3.2 Explore Fairness in Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "212507b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 103) (15060, 103) (30162,) (15060,)\n",
      "(700, 61) (300, 61) (700,) (300,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "# Dont't change code in this cell\n",
    "\n",
    "'''\n",
    ":train_x: the features in the training set (including the sensitive features), shape: N_train x d\n",
    ":train_y: the outcome in the training set, shape: N_train\n",
    ":test_x: the features in the test set (including the sensitive features), shape: N_test x d\n",
    ":test_y: the outcome in the test set, shape: N_test\n",
    ":test_sens: the sensitive/protected feature in the test set, shape: N_test\n",
    "All of them are processed numpy arrays that are ready for algorithms.\n",
    "'''\n",
    "\n",
    "\n",
    "# adult\n",
    "# the outcome (income) is the last column\n",
    "df_train_x_adult = df_train_adult.iloc[:, :-1]\n",
    "df_train_y_adult = df_train_adult.iloc[:, -1]\n",
    "df_test_x_adult = df_test_adult.iloc[:, :-1]\n",
    "df_test_y_adult = df_test_adult.iloc[:, -1]\n",
    "df_test_sens_adult = df_test_adult['sex']\n",
    "\n",
    "train_x_adult, test_x_adult = process_dfs(df_train_x_adult, df_test_x_adult, \n",
    "                                                   ['workclass', 'education','marital-status',\n",
    "                                                    'occupation','relationship','race',\n",
    "                                                    'native-country'])\n",
    "train_y_adult = df_train_y_adult.values\n",
    "test_y_adult = df_test_y_adult.values\n",
    "test_sens_adult = df_test_sens_adult.values\n",
    "\n",
    "# german\n",
    "# the outcome (credit status) is the last column\n",
    "df_train_x_german = df_train_german.iloc[:, :-1]\n",
    "df_train_y_german = df_train_german.iloc[:, -1]\n",
    "df_test_x_german = df_test_german.iloc[:, :-1]\n",
    "df_test_y_german = df_test_german.iloc[:, -1]\n",
    "df_test_sens_german = df_test_german['age']\n",
    "\n",
    "train_x_german, test_x_german = process_dfs(df_train_x_german, df_test_x_german,\n",
    "                                                     ['checking_account', 'credit_history', \n",
    "                                                      'purpose', 'savings_account', 'present_employment_since', \n",
    "                                                      'personal_status_sex', 'other_debtors',\n",
    "                                                     'property', 'other_installment_plans',\n",
    "                                                     'housing', 'job', 'telephone', 'foreign_worker'])\n",
    "train_y_german = df_train_y_german.values\n",
    "test_y_german = df_test_y_german.values\n",
    "test_sens_german = df_test_sens_german.values\n",
    "\n",
    "print(train_x_adult.shape, test_x_adult.shape, train_y_adult.shape, test_y_adult.shape)\n",
    "print(train_x_german.shape, test_x_german.shape, train_y_german.shape, test_y_german.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4060f120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8460823373173971 0.184314312558775 0.18437865629412392\n",
      "0.7566666666666667 -0.10337468320661602 -0.1276872861940182\n"
     ]
    }
   ],
   "source": [
    "# train a classifier to predict the outcome y from features x\n",
    "# training: train_x --> train_y; test: test_x --> preds\n",
    "# logistic regression model is recommended\n",
    "# sklearn is allowed to use\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Adult\n",
    "\n",
    "# initialize the model\n",
    "# TODO. 3pts\n",
    "model_adult = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# train/fit the model with train_x_adult and train_y_adult\n",
    "# TODO. 4pts\n",
    "model_adult.fit(train_x_adult, train_y_adult)\n",
    "\n",
    "# predict the outcome from test_x_adult\n",
    "# TODO. 3pts. The starter code below just indicate what you need to output in your code.\n",
    "preds = model_adult.predict(test_x_adult)\n",
    "\n",
    "\n",
    "# report acc and two fairness metrics. \n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_adult, preds)\n",
    "stat_p = stat_parity(preds, test_sens_adult)\n",
    "eq_op = eq_oppo(preds, test_sens_adult, test_y_adult)\n",
    "print(acc, stat_p, eq_op)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# German\n",
    "\n",
    "# initialize the model\n",
    "# TODO. 3pts\n",
    "model_german = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# train/fit the model with train_x_german and train_y_german\n",
    "# TODO. 4pts\n",
    "model_german.fit(train_x_german, train_y_german)\n",
    "\n",
    "\n",
    "# predict the outcome from test_x_german\n",
    "# TODO. 3pts. The starter code below just indicate what you need to output in your code.\n",
    "preds = model_german.predict(test_x_german)\n",
    "\n",
    "\n",
    "# report acc and two fairness metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_german, preds)\n",
    "stat_p = stat_parity(preds, test_sens_german)\n",
    "eq_op = eq_oppo(preds, test_sens_german, test_y_german)\n",
    "print(acc, stat_p, eq_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde8e5d4",
   "metadata": {},
   "source": [
    "## 4. Explore possible ways to mitigate bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b955793",
   "metadata": {},
   "source": [
    "### 4. 1 remove protected attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f484b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 102) (15060, 102)\n",
      "(700, 60) (300, 60)\n"
     ]
    }
   ],
   "source": [
    "# Adult\n",
    "# remove the sex column from df_train_x_adult and df_test_x_adult. \n",
    "# You shouldn't do it in-place. In other words, do not modify df_train_x_adult or df_test_x_adult\n",
    "# TODO. 2pts. The starter code below just indicate what you need to output in your code.\n",
    "df_train_x_no_sens_adult = df_train_x_adult.drop('sex', axis=1)\n",
    "df_test_x_no_sens_adult = df_test_x_adult.drop('sex', axis=1)\n",
    "\n",
    "\n",
    "train_x_adult, test_x_adult = process_dfs(df_train_x_no_sens_adult, df_test_x_no_sens_adult, \n",
    "                                                   ['workclass', 'education','marital-status',\n",
    "                                                    'occupation','relationship','race',\n",
    "                                                    'native-country'])\n",
    "\n",
    "\n",
    "# German\n",
    "# remove age column from df_train_x_german and df_test_x_german\n",
    "# You shouldn't do it in-place. In other words, do not modify df_train_x_german or df_test_x_german\n",
    "# TODO. 2pts. The starter code below just indicate what you need to output in your code.\n",
    "df_train_x_no_sens_german = df_train_x_german.drop('age', axis=1)\n",
    "df_test_x_no_sens_german = df_test_x_german.drop('age', axis=1)\n",
    "\n",
    "\n",
    "train_x_german, test_x_german = process_dfs(df_train_x_no_sens_german, df_test_x_no_sens_german,\n",
    "                                                     ['checking_account', 'credit_history', \n",
    "                                                      'purpose', 'savings_account', 'present_employment_since', \n",
    "                                                      'personal_status_sex', 'other_debtors',\n",
    "                                                     'property', 'other_installment_plans',\n",
    "                                                     'housing', 'job', 'telephone', 'foreign_worker'])\n",
    "\n",
    "\n",
    "print(train_x_adult.shape, test_x_adult.shape)\n",
    "print(train_x_german.shape, test_x_german.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4145617a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8457503320053121 0.17471816846799434 0.1493626846346902\n",
      "0.7633333333333333 -0.07643057222889149 -0.06114360700499011\n"
     ]
    }
   ],
   "source": [
    "# train a classifier to predict the outcome y from features x (with protected feature removed)\n",
    "# training: train_x --> train_y; test: test_x --> preds\n",
    "# logistic regression model is recommended\n",
    "# sklearn is allowed to use\n",
    "# Just use the code in 3.2 again\n",
    "\n",
    "\n",
    "# Adult\n",
    "\n",
    "# initialize the model\n",
    "# TODO. 0pt\n",
    "model_no_sens_adult = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# train/fit the model with train_x_adult and train_y_adult\n",
    "# TODO. 0pt\n",
    "model_no_sens_adult.fit(train_x_adult, train_y_adult)\n",
    "\n",
    "# predict the outcome from test_x_adult\n",
    "# TODO. 0pt. The starter code below just indicate what you need to output in your code.\n",
    "preds = model_no_sens_adult.predict(test_x_adult)\n",
    "\n",
    "# report acc and two fairness metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_adult, preds)\n",
    "stat_p = stat_parity(preds, test_sens_adult)\n",
    "eq_op = eq_oppo(preds, test_sens_adult, test_y_adult)\n",
    "print(acc, stat_p, eq_op)\n",
    "\n",
    "\n",
    "\n",
    "# German\n",
    "\n",
    "# initialize the model\n",
    "# TODO. 0pt\n",
    "model_no_sens_german = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# train/fit the model with train_x_german and train_y_german\n",
    "# TODO. 0pt\n",
    "model_no_sens_german.fit(train_x_german, train_y_german)\n",
    "\n",
    "# predict the outcome from test_x_german\n",
    "# TODO. 0pt. The starter code below just indicate what you need to output in your code.\n",
    "preds = model_no_sens_german.predict(test_x_german)\n",
    "\n",
    "# report acc and two fairness metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_german, preds)\n",
    "stat_p = stat_parity(preds, test_sens_german)\n",
    "eq_op = eq_oppo(preds, test_sens_german, test_y_german)\n",
    "print(acc, stat_p, eq_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0face94",
   "metadata": {},
   "source": [
    "### According to the results, how are the accuracy, stat parity and eq oppo different from the original model? Does explicitly removing the sensitive feature help in mitigating bias? Why or why not?\n",
    "### <span style=\"color:red\">Please type your response here.</span> 5pts\n",
    "\n",
    "1. The **accuracy score** of predicting adult dataset drops for 0.033201% which does not make a big difference in current circumstances. The accuracy score of german dataset increased for 0.666667%, indicating removing the sensitive feature could potentially improve the prediction but largely still does not show enough edivence of dependence.\n",
    "\n",
    "2. The **statistical parity** of adult dataset *drops* by 0.959614%, and that of german dataset *drops* by 2.694411%, both calculated in absolute values.\n",
    "\n",
    "2. The **Equalized oppo** of adult dataset *drops* by -3.501597%, and that of german dataset *drops* by 6.654368%, both calculated in absolute values.\n",
    "\n",
    "---\n",
    "\n",
    "Explicitly removing the sensitive feature does not necessarily completely remove bias but it can take effect to some extend. Reasons:\n",
    "\n",
    "1. Fairness Metrics decreased:\n",
    "\n",
    "Statistical parity and equalized opportunity both decreased, meaning reduced group disparities and improved fairness when the sensitive attribute was removed.\n",
    "\n",
    "2. Indirect Correlations Persist:\n",
    "\n",
    "Even if we remove sex from the Adult dataset and age from the German dataset, other features in the dataset may still be correlated with these sensitive attributes. For example, in the Adult dataset, occupation, marital status, and relationship may serve as proxies for sex. In the German dataset, features like employment status or credit history might correlate with age.\n",
    "As a result, the model can still infer the sensitive feature from other variables, leading to biased predictions despite its removal.\n",
    "\n",
    "3. Accuracy Trade-off:\n",
    "\n",
    "In the German dataset, accuracy slightly improved after removing the sensitive feature, but in the Adult dataset, it slightly dropped. This shows that sensitive features may sometimes contribute useful information for prediction, so their removal does not always improve fairness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2279414",
   "metadata": {},
   "source": [
    "### 4.2 Augmenting the training set\n",
    "\n",
    "#### See the example in Figure 1 of https://dl.acm.org/doi/pdf/10.1145/3375627.3375865"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a69738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_x_aug_adult:  (60324, 14) \n",
      "df_train_y_aug_adult:  (60324,)\n",
      "\n",
      "train_x_adult:  (60324, 103) \n",
      "test_x_adult:  (15060, 103) \n",
      "train_y_adult:  (60324,)\n",
      "(1400, 20) (1400,) (1400,)\n",
      "(1400, 61) (300, 61)\n"
     ]
    }
   ],
   "source": [
    "# Adult\n",
    "# create a synthetic training set by duplicating df_train_x_adult and df_train_y_adult\n",
    "# after duplicating flip sex in the synthetic set\n",
    "# You shouldn't do it in-place. In other words, do not modify df_train_x_adult or df_train_y_adult\n",
    "# TODO. 3pts. The starter code below just indicate what you need to output in your code.\n",
    "df_train_x_syn_adult = df_train_x_adult.copy()\n",
    "df_train_y_syn_adult = df_train_y_adult.copy()\n",
    "\n",
    "df_train_x_syn_adult['sex'] = 1 - df_train_x_syn_adult['sex']\n",
    "\n",
    "# augment the original training set by the synthetic set. In other words, concatenate them\n",
    "df_train_x_aug_adult = pd.concat((df_train_x_adult, df_train_x_syn_adult))\n",
    "df_train_y_aug_adult = pd.concat((df_train_y_adult, df_train_y_syn_adult))\n",
    "\n",
    "print(\"df_train_x_aug_adult: \", df_train_x_aug_adult.shape, \"\\ndf_train_y_aug_adult: \", df_train_y_aug_adult.shape)\n",
    "\n",
    "\n",
    "train_x_adult, test_x_adult = process_dfs(df_train_x_aug_adult, df_test_x_adult, \n",
    "                                                   ['workclass', 'education','marital-status',\n",
    "                                                    'occupation','relationship','race',\n",
    "                                                    'native-country'])\n",
    "train_y_adult = df_train_y_aug_adult.values\n",
    "print(\"\\ntrain_x_adult: \", train_x_adult.shape, \"\\ntest_x_adult: \", test_x_adult.shape, \"\\ntrain_y_adult: \", train_y_adult.shape)\n",
    "\n",
    "\n",
    "\n",
    "# German\n",
    "# create a synthetic training set by duplicating df_train_x_german and df_train_y_german\n",
    "# after duplicating flip age in the synthetic set.\n",
    "# You shouldn't do it in-place. In other words, do not modify df_train_x_german or df_train_y_german\n",
    "# TODO. 3pts. The starter code below just indicate what you need to output in your code.\n",
    "df_train_x_syn_german = df_train_x_german.copy()\n",
    "df_train_y_syn_german = df_train_y_german.copy()\n",
    "\n",
    "df_train_x_syn_german['age'] = 1 - df_train_x_syn_german['age']\n",
    "\n",
    "# augment the original training set by the synthetic set. In other words, concatenate them\n",
    "df_train_x_aug_german = pd.concat((df_train_x_german, df_train_x_syn_german))\n",
    "df_train_y_aug_german = pd.concat((df_train_y_german, df_train_y_syn_german))\n",
    "\n",
    "train_y_german = df_train_y_aug_german.values\n",
    "\n",
    "print(df_train_x_aug_german.shape, df_train_y_aug_german.shape, train_y_german.shape)\n",
    "\n",
    "\n",
    "train_x_german, test_x_german = process_dfs(df_train_x_aug_german, df_test_x_german,\n",
    "                                                     ['checking_account', 'credit_history', \n",
    "                                                      'purpose', 'savings_account', 'present_employment_since', \n",
    "                                                      'personal_status_sex', 'other_debtors',\n",
    "                                                     'property', 'other_installment_plans',\n",
    "                                                     'housing', 'job', 'telephone', 'foreign_worker'])\n",
    "print(train_x_german.shape, test_x_german.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1791c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846879150066401 0.17517229075356358 0.14869682804369228\n",
      "0.7633333333333333 -0.07643057222889149 -0.06114360700499011\n"
     ]
    }
   ],
   "source": [
    "# train a classifier to predict the outcome y from features x on the augmented training data\n",
    "# training: train_x --> train_y; test: test_x --> preds\n",
    "# logistic regression model is recommended\n",
    "# sklearn is allowed to use\n",
    "# Just use the code in 3.2 again\n",
    "\n",
    "\n",
    "# Adult\n",
    "\n",
    "# initialize the model\n",
    "# TODO. 3pts\n",
    "model_adult = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# train/fit the model with train_x_adult and train_y_adult\n",
    "# TODO. 4pts\n",
    "model_adult.fit(train_x_adult, train_y_adult)\n",
    "\n",
    "# predict the outcome from test_x_adult\n",
    "# TODO. 3pts. The starter code below just indicate what you need to output in your code.\n",
    "preds = model_adult.predict(test_x_adult)\n",
    "\n",
    "\n",
    "# report acc and two fairness metrics. \n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_adult, preds)\n",
    "stat_p = stat_parity(preds, test_sens_adult)\n",
    "eq_op = eq_oppo(preds, test_sens_adult, test_y_adult)\n",
    "print(acc, stat_p, eq_op)\n",
    "\n",
    "\n",
    "\n",
    "# German\n",
    "\n",
    "# initialize the model\n",
    "# TODO. 3pts\n",
    "model_german = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# train/fit the model with train_x_german and train_y_german\n",
    "# TODO. 4pts\n",
    "model_german.fit(train_x_german, train_y_german)\n",
    "\n",
    "\n",
    "# predict the outcome from test_x_german\n",
    "# TODO. 3pts. The starter code below just indicate what you need to output in your code.\n",
    "preds = model_german.predict(test_x_german)\n",
    "\n",
    "\n",
    "# report acc and two fairness metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_german, preds)\n",
    "stat_p = stat_parity(preds, test_sens_german)\n",
    "eq_op = eq_oppo(preds, test_sens_german, test_y_german)\n",
    "print(acc, stat_p, eq_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adcf17e",
   "metadata": {},
   "source": [
    "### According to the results, how are the accuracy, stat parity and eq oppo different from the original model? Does augmenting the dataset with synthetic data help in mitigating bias? Why or why not?\n",
    "### <span style=\"color:red\">Please type your response here.</span> 5pts\n",
    "\n",
    "1. Accuracy\n",
    "There is a slight increase in accuracy for both datasets after augmenting with synthetic data.\n",
    "The improvement is more noticeable for the German dataset (+0.00667) compared to the Adult dataset (+0.0008).\n",
    "2. Statistical Parity\n",
    "Adult Dataset: Stat parity decreased slightly (-0.0091), meaning the gap between groups increased slightly.\n",
    "German Dataset: Stat parity increased (+0.0269), which means the gap between groups was reduced.\n",
    "3. Equalized Opportunity\n",
    "Adult Dataset: Eq oppo decreased (-0.0357), suggesting an increased disparity in the true positive rates across groups.\n",
    "German Dataset: Eq oppo increased significantly (+0.0665), meaning the true positive rates between groups became more balanced.\n",
    "\n",
    "---\n",
    "\n",
    "Question: Does Augmenting the Dataset with Synthetic Data Help in Mitigating Bias?\n",
    "* For the German dataset: Yes, it seems to have reduced bias, as statistical parity and equalized opportunity both improved while accuracy remained stable or increased.\n",
    "* For the Adult dataset: No, it did not significantly mitigate bias. Although accuracy remained stable, both fairness metrics (stat parity and eq oppo) worsened slightly.\n",
    "\n",
    "Reasons:\n",
    "* Effectiveness depends on dataset structure: The German dataset benefited more from augmentation, possibly due to its smaller size or greater imbalance in the original data.\n",
    "* Synthetic balancing does not always improve fairness: While balancing the dataset by flipping sex creates a more representative distribution, it does not necessarily correct underlying biases in the model's decision-making.\n",
    "* Trade-off between accuracy and fairness: In the Adult dataset, fairness metrics worsened slightly, suggesting that bias might still exist even after augmentation.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "Augmenting the dataset with synthetic data may help in mitigating bias, but its effectiveness depends on the dataset. In this case, it helped for the German dataset but not for the Adult dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
